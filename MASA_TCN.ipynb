{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnE4xXxQQChK",
        "outputId": "44586611-97a6-471c-b26d-a8118f03da43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeaqkIl0JvJc",
        "outputId": "40c9c0f1-7a21-45a4-cadc-252c1f20acd7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.3.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchvision) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchvision) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n",
            "Collecting einops\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.8.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.40)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.30.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchsummary\n",
        "!pip install torchvision\n",
        "!pip install scipy\n",
        "!pip install einops\n",
        "!pip install transformers\n",
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R54lfNKJQ4b7"
      },
      "outputs": [],
      "source": [
        "!cd /content/drive/MyDrive/be_lab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9acubYRJTl2"
      },
      "outputs": [],
      "source": [
        "\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import scipy.io\n",
        "import random\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchsummary import summary\n",
        "import torch.autograd as autograd\n",
        "from torchvision.models import vgg19\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn.init as init\n",
        "from torch import Tensor\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from einops import rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "\n",
        "\n",
        "from torch.backends import cudnn\n",
        "cudnn.benchmark = False\n",
        "cudnn.deterministic = True\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from torch.nn import MSELoss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk5Xe7q6JVY5"
      },
      "source": [
        "\n",
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import weight_norm\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "\n",
        "class Chomp2d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp2d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "\n",
        "class TemporalBlockPro(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super(TemporalBlockPro, self).__init__()\n",
        "        # Define the convolutional layers without applying weight_norm here\n",
        "        conv1 = nn.Conv2d(n_inputs, n_outputs, (1, kernel_size),\n",
        "                          stride=stride, padding=(0, padding), dilation=(1, dilation))\n",
        "        conv2 = nn.Conv2d(n_outputs, n_outputs, (1, kernel_size),\n",
        "                          stride=stride, padding=(0, padding), dilation=(1, dilation))\n",
        "\n",
        "        # Apply weight_norm directly in the sequential model\n",
        "        self.net = nn.Sequential(\n",
        "            weight_norm(conv1), Chomp2d(padding), nn.PReLU(), nn.Dropout(dropout),\n",
        "            weight_norm(conv2), Chomp2d(padding), nn.PReLU(), nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        self.downsample = nn.Conv2d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        if self.downsample is not None:\n",
        "            self.downsample = weight_norm(self.downsample)\n",
        "        self.relu = nn.PReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        # Initialize weights for conv1 and conv2 if needed. Since weight_norm is applied within the sequential,\n",
        "        # you might need to access the first and fifth layers of self.net for weight initialization, if necessary.\n",
        "        pass  # Add weight initialization code here if needed\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "\n",
        "class TemporalConvNetPro(nn.Module):\n",
        "    def __init__(self, num_channels, num_eeg_chan=32, freq=6, kernel_size=2, dropout=0.2, early_fusion=True):\n",
        "        super(TemporalConvNetPro, self).__init__()\n",
        "        self.early_fusion = early_fusion\n",
        "        if early_fusion:\n",
        "            self.fusion_layer = weight_norm(nn.Conv2d(\n",
        "                in_channels=num_channels[0], out_channels=num_channels[0],\n",
        "                kernel_size=(num_eeg_chan, 1), stride=(1, 1)\n",
        "            ))\n",
        "        else:\n",
        "            self.fusion_layer = nn.Identity()\n",
        "        self.space_aware_temporal_layer = nn.Sequential(\n",
        "            weight_norm(nn.Conv2d(\n",
        "                in_channels=1, out_channels=num_channels[0],\n",
        "                kernel_size=(freq, kernel_size), stride=(freq, 1),\n",
        "                dilation=(1, 2), padding=(0, ((kernel_size - 1) * 2)))),\n",
        "            Chomp2d((kernel_size - 1) * 2),\n",
        "            nn.PReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            self.fusion_layer\n",
        "        )\n",
        "        layers = []\n",
        "        num_levels = len(num_channels) - 1\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** (i+2)\n",
        "            in_channels = num_channels[i] if i == 0 else num_channels[i]\n",
        "            out_channels = num_channels[i+1]\n",
        "            layers += [TemporalBlockPro(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
        "                                     padding=int((kernel_size - 1) * dilation_size), dropout=dropout)]\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.space_aware_temporal_layer[0].weight.data.normal_(0, 0.01)\n",
        "        if self.early_fusion:\n",
        "            self.fusion_layer.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.space_aware_temporal_layer(x)\n",
        "        return self.network(x)\n",
        "\n",
        "\n",
        "class SpaceAwareTemporalBlock(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=32, num_eeg_chan=32, freq=6, kernel_size=2, dropout=0.2, early_fusion=True):\n",
        "        super(SpaceAwareTemporalBlock, self).__init__()\n",
        "        self.early_fusion = early_fusion\n",
        "        # Initialize the fusion layer for early fusion\n",
        "        if early_fusion:\n",
        "            self.fusion_layer = weight_norm(nn.Conv2d(\n",
        "                in_channels=out_channels, out_channels=out_channels,\n",
        "                kernel_size=(num_eeg_chan, 1), stride=(1, 1)\n",
        "            ))\n",
        "        else:\n",
        "            self.fusion_layer = nn.Identity()\n",
        "\n",
        "        # Use self.fusion_layer directly if early_fusion is False, otherwise create a separate instance for the sequential model\n",
        "        fusion_layer_for_sequential = self.fusion_layer if not early_fusion else weight_norm(nn.Conv2d(\n",
        "            in_channels=out_channels, out_channels=out_channels,\n",
        "            kernel_size=(num_eeg_chan, 1), stride=(1, 1)\n",
        "        ))\n",
        "\n",
        "        self.space_aware_temporal_layer = nn.Sequential(\n",
        "            weight_norm(nn.Conv2d(\n",
        "                in_channels=in_channels, out_channels=out_channels,\n",
        "                kernel_size=(freq, kernel_size), stride=(freq, 1),\n",
        "                dilation=(1, 2), padding=(0, ((kernel_size - 1) * 2)))),\n",
        "            Chomp2d((kernel_size - 1) * 2),\n",
        "            nn.PReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            fusion_layer_for_sequential\n",
        "        )\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.space_aware_temporal_layer(x)\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.space_aware_temporal_layer[0].weight.data.normal_(0, 0.01)\n",
        "        if self.early_fusion:\n",
        "            # Initialize weights for the fusion layer used in the sequential model\n",
        "            self.space_aware_temporal_layer[4].weight.data.normal_(0, 0.01)\n",
        "            # Also initialize weights for the self.fusion_layer if it's going to be used elsewhere\n",
        "            self.fusion_layer.weight.data.normal_(0, 0.01)\n",
        "\n",
        "\n",
        "class TemporalConvNetProM(nn.Module):\n",
        "    def __init__(self, num_channels, num_eeg_chan=32, freq=6, kernel_size=[2, 4, 6], dropout=0.2, early_fusion=True):\n",
        "        super(TemporalConvNetProM, self).__init__()\n",
        "        self.early_fusion = early_fusion\n",
        "        self.sa_tcn_1 = SpaceAwareTemporalBlock(\n",
        "            out_channels=num_channels[0], num_eeg_chan=num_eeg_chan,\n",
        "            freq=freq, kernel_size=kernel_size[0], dropout=dropout, early_fusion=early_fusion)\n",
        "\n",
        "        self.sa_tcn_2 = SpaceAwareTemporalBlock(\n",
        "            out_channels=num_channels[0], num_eeg_chan=num_eeg_chan,\n",
        "            freq=freq, kernel_size=kernel_size[1], dropout=dropout, early_fusion=early_fusion)\n",
        "\n",
        "        self.sa_tcn_3 = SpaceAwareTemporalBlock(\n",
        "            out_channels=num_channels[0], num_eeg_chan=num_eeg_chan,\n",
        "            freq=freq, kernel_size=kernel_size[2], dropout=dropout, early_fusion=early_fusion)\n",
        "\n",
        "        layers = []\n",
        "        num_levels = len(num_channels) - 1\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** (i+2)\n",
        "            in_channels = num_channels[i]\n",
        "            out_channels = num_channels[i+1]\n",
        "            layers += [TemporalBlockPro(in_channels, out_channels, kernel_size[1], stride=1, dilation=dilation_size,\n",
        "                                     padding=int((kernel_size[1] - 1) * dilation_size), dropout=dropout)]\n",
        "\n",
        "        self.OneByOneConv = weight_norm(nn.Conv2d(\n",
        "                in_channels=3*num_channels[0], out_channels=num_channels[0],\n",
        "                kernel_size=(1, 1), stride=(1, 1)\n",
        "            ))\n",
        "        self.OneByOneConv.weight.data.normal_(0, 0.01)\n",
        "        self.pure_temporal_layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.sa_tcn_1(x)\n",
        "        x2 = self.sa_tcn_2(x)\n",
        "        x3 = self.sa_tcn_3(x)\n",
        "\n",
        "        x = torch.cat((x1, x2, x3), dim=1)\n",
        "        x = self.OneByOneConv(x)\n",
        "        return self.pure_temporal_layers(x)"
      ],
      "metadata": {
        "id": "_RTKIPr_PVrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0O1CCsQMrMT9"
      },
      "outputs": [],
      "source": [
        "# from temporal_convolutional_layers import TemporalConvNetPro, TemporalConvNetProM\n",
        "\n",
        "\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "\n",
        "class SA_TCN(nn.Module):\n",
        "    def __init__(self, cnn1d_channels=[128, 128, 128], cnn1d_kernel_size=5,\n",
        "                 cnn1d_dropout_rate=0.1, num_eeg_chan=32, freq=6, output_dim=1, early_fusion=True, model_type='reg'):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.mode = model_type\n",
        "        if self.mode == 'cls':\n",
        "            assert output_dim > 1, \"This model support at least binary classification. output_dim should > 1.\"\n",
        "        self.temporal = TemporalConvNetPro(num_channels=cnn1d_channels, num_eeg_chan=num_eeg_chan, freq=freq,\n",
        "                                           kernel_size=cnn1d_kernel_size, dropout=cnn1d_dropout_rate,\n",
        "                                           early_fusion=early_fusion)\n",
        "        self.regressor = nn.Linear(cnn1d_channels[-1], output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: batch, 1, hidden, seq\n",
        "        x = self.temporal(x).transpose(1, 3).contiguous()\n",
        "        x = x.squeeze(-2)\n",
        "        x = self.regressor(x).contiguous()\n",
        "        if self.mode == 'cls':\n",
        "            x = torch.mean(x, dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MASA_TCN(nn.Module):\n",
        "    def __init__(self, cnn1d_channels=[128, 128, 128], cnn1d_kernel_size=[3, 5, 15],\n",
        "                 cnn1d_dropout_rate=0.1, num_eeg_chan=32, freq=6,\n",
        "                 output_dim=1, early_fusion=True, model_type='reg'):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.mode = model_type\n",
        "        if self.mode == 'cls':\n",
        "            assert output_dim > 1, \"This model support at least binary classification. output_dim should > 1.\"\n",
        "        self.temporal = TemporalConvNetProM(num_channels=cnn1d_channels, num_eeg_chan=num_eeg_chan, freq=freq,\n",
        "                                            kernel_size=cnn1d_kernel_size, dropout=cnn1d_dropout_rate,\n",
        "                                            early_fusion=early_fusion)\n",
        "        self.regressor = nn.Linear(cnn1d_channels[-1], output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: batch, 1, hidden, seq\n",
        "        x = self.temporal(x).transpose(1, 3).contiguous()\n",
        "        x = x.squeeze(-2)\n",
        "        x = self.regressor(x).contiguous()\n",
        "        if self.mode == 'cls':\n",
        "            x = torch.mean(x, dim=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGsml7yNrQ7G"
      },
      "outputs": [],
      "source": [
        "class MASATCNforTraining(nn.Module):\n",
        "    def __init__(self, **kwargs) -> None:\n",
        "        super(MASATCNforTraining, self).__init__()\n",
        "        self.network = MASA_TCN(cnn1d_channels=[128, 128, 128],\n",
        "                                cnn1d_kernel_size=[3, 5, 15],\n",
        "                                cnn1d_dropout_rate=0.1,\n",
        "                                num_eeg_chan=5000,\n",
        "                                freq=1,\n",
        "                                output_dim=1,\n",
        "                                early_fusion=True,\n",
        "                                model_type='reg')\n",
        "\n",
        "    def forward(self, input, label = None):\n",
        "        #print(input.shape)\n",
        "        input = input.unsqueeze(1)\n",
        "        # print(input.shape)\n",
        "        input = torch.transpose(input, 2, 3)\n",
        "        # print(input.shape)\n",
        "        input = input.reshape(4, 1, -1)\n",
        "        input = input.unsqueeze(-1)\n",
        "        # print(input.shape)\n",
        "        outputs = self.network(input)\n",
        "        # print(\"outputs.shape = \",outputs.shape)\n",
        "        outputs = outputs.squeeze(-1)\n",
        "        # print(\"outputs.shape = \",outputs.shape)\n",
        "        outputs = outputs.transpose(0, 1)\n",
        "        # print(\"outputs.shape = \",outputs.shape)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YprLoZ75rDZi"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "def pad_collate(batch):\n",
        "    # Extract inputs and labels from the batch\n",
        "    inputs = [item['input'] for item in batch]\n",
        "    labels = [item['label'] for item in batch]\n",
        "\n",
        "    # Check if the batch size is not a multiple of 4\n",
        "    required_batch_size = batch_size\n",
        "    shortfall = len(batch) % required_batch_size\n",
        "    if shortfall > 0:\n",
        "        # Calculate how many samples to add\n",
        "        samples_to_add = required_batch_size - shortfall\n",
        "        # Randomly select samples to add\n",
        "        for _ in range(samples_to_add):\n",
        "            random_sample = random.choice(batch)  # Assuming 'random' is already imported\n",
        "            inputs.append(random_sample['input'])\n",
        "            labels.append(random_sample['label'])\n",
        "\n",
        "    # Pad the inputs to have the same length\n",
        "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
        "\n",
        "    # Stack labels into a single tensor\n",
        "    labels = torch.stack(labels)\n",
        "\n",
        "    return {'input': inputs_padded, 'label': labels}\n",
        "\n",
        "\n",
        "\n",
        "class EEGDataset(Dataset):\n",
        "    def __init__(self, root_dir, max_timesteps=1000):\n",
        "        self.max_timesteps = max_timesteps\n",
        "        self.data_files = []\n",
        "        self.portion_counts = []  # Store the number of portions per file\n",
        "        self.labels = []\n",
        "        for folder_name in os.listdir(root_dir):\n",
        "            if '(' in folder_name and ')' in folder_name:\n",
        "                label = int(folder_name.split('(')[-1].split(')')[0])\n",
        "                folder_path = os.path.join(root_dir, folder_name)\n",
        "                for file_name in os.listdir(folder_path):\n",
        "                    if file_name.endswith('.mat') and file_name != 'FFT.mat':\n",
        "                        file_path = os.path.join(folder_path, file_name)\n",
        "                        self.data_files.append(file_path)\n",
        "                        self.labels.append(label)\n",
        "                        # Determine how many portions this file will be split into\n",
        "                        data = scipy.io.loadmat(file_path)['data']\n",
        "                        portions = math.ceil(data.shape[1] / max_timesteps)\n",
        "                        self.portion_counts.append(portions)\n",
        "\n",
        "    def __len__(self):\n",
        "        return sum(self.portion_counts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Find which file and which portion this index corresponds to\n",
        "        file_idx = 0\n",
        "        while idx >= self.portion_counts[file_idx]:\n",
        "            idx -= self.portion_counts[file_idx]\n",
        "            file_idx += 1\n",
        "        portion_idx = idx\n",
        "        label = self.labels[file_idx]\n",
        "        data_path = self.data_files[file_idx]\n",
        "        data = scipy.io.loadmat(data_path)['data']\n",
        "        # Calculate the start and end indices for this portion\n",
        "        start_idx = portion_idx * self.max_timesteps\n",
        "        end_idx = min((portion_idx + 1) * self.max_timesteps, data.shape[1])\n",
        "        #print(end_idx)\n",
        "        # Slice the data for this portion\n",
        "        data_portion = data[:, start_idx:end_idx]\n",
        "        data_portion = torch.tensor(data_portion, dtype=torch.float32)\n",
        "        return {'input': data_portion, 'label_ids': label, 'label': torch.tensor(label, dtype=torch.long)}\n",
        "\n",
        "def model_init():\n",
        "    return MASATCNforTraining()  # Initialize your modified Conformer model here\n",
        "\n",
        "\n",
        "\n",
        "data_collator = pad_collate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTrainer(Trainer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_fn = MSELoss()\n",
        "        # self.total_loss = []\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs[\"label\"].float()  # Ensure labels are float for MSE Loss\n",
        "        outputs = model(**inputs)\n",
        "        # Reshape labels to match output shape (batch_size, 1)\n",
        "        labels = labels.view(-1, 1)\n",
        "        labels = labels.transpose(0, 1)\n",
        "        loss = self.loss_fn(outputs, labels)\n",
        "        print(loss)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/be_lab/results',\n",
        "    num_train_epochs=2000,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    logging_dir='/content/drive/MyDrive/be_lab/logs',\n",
        "    logging_steps=10,\n",
        "    learning_rate=2e-4,\n",
        "    lr_scheduler_type='cosine',\n",
        "    save_steps=2000,\n",
        "    warmup_steps=1000,\n",
        "    warmup_ratio=0.1,\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=EEGDataset(root_dir='/content/drive/MyDrive/be_lab/data/G01_data_cut'),\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "#trainer.train()\n",
        "\n",
        "trainer.train(resume_from_checkpoint = \"/content/drive/MyDrive/be_lab/results/checkpoint-23500\")"
      ],
      "metadata": {
        "id": "8kINQsy3gYcH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "outputId": "bfcd90ff-f026-4237-bc1e-d41f3587c8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23517' max='140000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 23517/140000 00:07 < 15:48:52, 2.05 it/s, Epoch 335.94/2000]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>23510</td>\n",
              "      <td>0.027100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0093, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0078, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0098, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0388, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0105, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.1229, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9d62579f02a5>\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m#trainer.train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# print(torch.tensor(trainer.total_loss).sum()/len(trainer.total_loss))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/be_lab/results/checkpoint-23500\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;31m# resume_from_checkpoint = \"/content/drive/MyDrive/be_lab/results/checkpoint-2000\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1885\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1886\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2215\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2216\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2218\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3237\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3238\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3240\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-9d62579f02a5>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure labels are float for MSE Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Reshape labels to match output shape (batch_size, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c59b8d1c5d8d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, label)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# print(input.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# print(\"outputs.shape = \",outputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-465a8f662069>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# x: batch, 1, hidden, seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-8f82067e03b4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa_tcn_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa_tcn_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msa_tcn_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-8f82067e03b4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace_aware_temporal_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m                 for hook_id, hook in (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC0XSKsdFy_D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92700f6e-e1dd-4427-a898-4c4f11a37a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 36\n",
            "First item keys: dict_keys(['input', 'label_ids', 'label'])\n",
            "tensor([[6.0561, 6.1385, 6.0997, 6.0975]], device='cuda:0')\n",
            "tensor([2, 2, 2, 2], device='cuda:0')\n",
            "tensor([[6.1770, 6.0823, 6.2026, 6.2342]], device='cuda:0')\n",
            "tensor([2, 2, 2, 2], device='cuda:0')\n",
            "tensor([[6.0958, 6.1466, 6.1128, 6.0714]], device='cuda:0')\n",
            "tensor([2, 2, 2, 2], device='cuda:0')\n",
            "tensor([[6.0429, 6.0566, 6.2597, 6.1044]], device='cuda:0')\n",
            "tensor([2, 2, 2, 2], device='cuda:0')\n",
            "tensor([[6.2077, 6.0727, 6.0580, 5.9936]], device='cuda:0')\n",
            "tensor([2, 2, 2, 2], device='cuda:0')\n",
            "tensor([[6.1385, 6.1807, 6.0883, 6.0869]], device='cuda:0')\n",
            "tensor([2, 2, 2, 2], device='cuda:0')\n",
            "tensor([[6.0639, 6.1535, 6.0720, 6.1266]], device='cuda:0')\n",
            "tensor([2, 2, 2, 2], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6.1511, 6.6996, 6.0542, 6.0765]], device='cuda:0')\n",
            "tensor([2, 2, 2, 2], device='cuda:0')\n",
            "tensor([[6.1348, 6.0159, 6.1512, 6.1009]], device='cuda:0')\n",
            "tensor([2, 2, 2, 2], device='cuda:0')\n",
            "average_error =  tensor(4.1279, device='cuda:0')\n",
            "batches =  9\n",
            "total_error =  tensor(148.6045, device='cuda:0')\n",
            "len of dataset =  36\n",
            "average =  tensor(5.9623, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c98e4ec6-8afe-4bfa-98ee-fbefcf0a07ca\", \"final1.png\", 26135)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "!set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
        "from safetensors.torch import load_model, save_model\n",
        "from scipy.signal import savgol_filter\n",
        "import matplotlib.pyplot as plt\n",
        "#PYTORCH_CUDA_ALLOC_CONF=expandable_segments\n",
        "\n",
        "time_global = 0\n",
        "score_global = 0\n",
        "\n",
        "def perform_inference():\n",
        "    # Initialize the model\n",
        "    model = trainer.model\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # DataLoader for inference dataset\n",
        "    inference_dataset = EEGDataset(root_dir='/content/drive/MyDrive/be_lab/data/inference2')  # Use the provided data directory\n",
        "    inference_loader = DataLoader(inference_dataset, batch_size=4, collate_fn=pad_collate)\n",
        "\n",
        "    # Check the size of the dataset\n",
        "    print(f\"Dataset size: {len(inference_dataset)}\")\n",
        "\n",
        "    # Try to get the first item from the dataset\n",
        "    if len(inference_dataset) > 0:\n",
        "        first_item = inference_dataset[0]\n",
        "        print(f\"First item keys: {first_item.keys()}\")\n",
        "    else:\n",
        "        print(\"Dataset is empty. Check the dataset path and contents.\")\n",
        "\n",
        "    total_error = 0\n",
        "    batches = 0\n",
        "    total_score = 0\n",
        "    scores = []\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():  # No need to track gradients\n",
        "        for batch in inference_loader:\n",
        "            batches += 1\n",
        "            inputs = batch['input']\n",
        "            inputs = inputs.to(torch.device('cuda:0'))\n",
        "            true_labels = batch['label'].to(torch.device('cuda:0'))  # Assuming you want to compare against true labels\n",
        "            outputs = model(inputs)\n",
        "            print(outputs)\n",
        "            print(true_labels)\n",
        "            predicted_labels = outputs.to(torch.device('cuda:0'))\n",
        "            total_error += abs(predicted_labels - true_labels).sum()\n",
        "            total_score += (predicted_labels).sum()\n",
        "            for x in predicted_labels:\n",
        "                scores.append(x[0].cpu().numpy().item())\n",
        "                scores.append(x[1].cpu().numpy().item())\n",
        "                scores.append(x[2].cpu().numpy().item())\n",
        "                scores.append(x[3].cpu().numpy().item())\n",
        "\n",
        "    print(\"average_error = \", total_error / batches / 4)\n",
        "    print(\"batches = \", batches)\n",
        "    print(\"total_error = \", total_error)\n",
        "    print(\"len of dataset = \", len(inference_dataset))\n",
        "\n",
        "    concentration_time = len(inference_dataset) * 4 / 60\n",
        "    average_score = total_score / (len(inference_dataset)+1)\n",
        "    print(\"average = \",average_score)\n",
        "\n",
        "\n",
        "    # Create time axis (list index)\n",
        "    time = list(range(len(scores)))\n",
        "    time = np.array(time)\n",
        "    time = 5 * time * (1/60)\n",
        "    time_global = len(time)*5/60\n",
        "    score_global = average_score\n",
        "\n",
        "    # Create a figure with a smaller width and larger height to accommodate the caption\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 10))\n",
        "\n",
        "    # Plot the data\n",
        "    ax.plot(time, scores, marker='o', linestyle='-', color='red')\n",
        "\n",
        "    # Set the title and labels for the plot\n",
        "\n",
        "    ax.set_xlabel('Time (Min)')\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.set_ylim(0, 10)\n",
        "\n",
        "    # Add a legend\n",
        "    ax.legend()\n",
        "\n",
        "    # Adjust the layout to make space for the caption\n",
        "    plt.tight_layout(rect=[0, 0.1, 1, 0.95])\n",
        "\n",
        "    # Save the figure with the caption\n",
        "    plt.savefig('final1.png', bbox_inches='tight', dpi=150)\n",
        "\n",
        "    return time_global, score_global\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "\n",
        "time_global, score_global = perform_inference()\n",
        "\n",
        "from google.colab import files\n",
        "files.download('final1.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google\n",
        "!pip install google-api-python-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBa4It7zOG5u",
        "outputId": "1caf520a-21c7-43e0-f948-651b5ea8c859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from google) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->google) (2.5)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.84.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.63.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 安裝必要的套件\n",
        "!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
        "\n",
        "# 授權並设置Google Drive和Google Docs API\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.credentials import Credentials"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "o6Izg4Ak8uAt",
        "outputId": "f99973af-a59d-4e35-d8f1-aad399d68891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.130.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.27.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.63.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.1.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 授權\n",
        "auth.authenticate_user()\n",
        "\n",
        "# 初始化Google Drive API\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "# 初始化Google Docs API\n",
        "docs_service = build('docs', 'v1')\n",
        "\n",
        "# 創建或打開名為analysis的Google Docs文档\n",
        "def create_or_open_doc(doc_title):\n",
        "    # 檢查是否已存在名為analysis的文档\n",
        "    results = drive_service.files().list(q=f\"name='{doc_title}' and mimeType='application/vnd.google-apps.document' and trashed=false\").execute()\n",
        "    items = results.get('files', [])\n",
        "    if not items:\n",
        "        # 創建新文檔\n",
        "        doc = docs_service.documents().create(body={'title': doc_title}).execute()\n",
        "        doc_id = doc['documentId']\n",
        "    else:\n",
        "        # 打開已存在的文檔\n",
        "        doc_id = items[0]['id']\n",
        "    return doc_id\n",
        "\n",
        "# 將圖片設置為公開訪問\n",
        "def make_file_public(file_id):\n",
        "    drive_service.permissions().create(\n",
        "        fileId=file_id,\n",
        "        body={'role': 'reader', 'type': 'anyone'},\n",
        "    ).execute()\n",
        "\n",
        "# 添加圖片和文字到文檔\n",
        "def add_content_to_doc(doc_id, text, image_path):\n",
        "    # 上传图片到Google Drive\n",
        "    file_metadata = {'name': image_path.split('/')[-1], 'mimeType': 'image/jpeg'}\n",
        "    media = MediaFileUpload(image_path, mimetype='image/jpeg')\n",
        "    image_file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "\n",
        "    # 設置圖片為公開訪問\n",
        "    make_file_public(image_file['id'])\n",
        "\n",
        "    image_url = f\"https://drive.google.com/uc?id={image_file['id']}\"\n",
        "\n",
        "    # 插入文字和圖片\n",
        "    requests = [\n",
        "        {'insertText': {'location': {'index': 1}, 'text': text + '\\n'}},\n",
        "        {'insertInlineImage': {'location': {'index': 1}, 'uri': image_url, 'objectSize': {'height': {'magnitude': 300, 'unit': 'PT'}, 'width': {'magnitude': 300, 'unit': 'PT'}}}},\n",
        "        {'insertPageBreak': {'location': {'index': 1}}}  # 插入分頁符\n",
        "    ]\n",
        "\n",
        "    docs_service.documents().batchUpdate(documentId=doc_id, body={'requests': requests}).execute()\n",
        "\n",
        "# 主程序\n",
        "def write():\n",
        "    doc_title = \"| 專心測試結果\"\n",
        "    doc_id = create_or_open_doc(doc_title)\n",
        "\n",
        "    # while True:\n",
        "        # 請用戶上傳圖片和輸入文字\n",
        "    from google.colab import files\n",
        "\n",
        "    print(\"請上傳圖片\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        image_path = f\"/content/{filename}\"\n",
        "        text = f' \\n \\n \\n Concentration time = {time_global} min \\n \\n Average Score = {score_global} ' + '\\n' + '\\n'\n",
        "        for i in range(20):\n",
        "            text += '\\n'\n",
        "        add_content_to_doc(doc_id, text, image_path)\n",
        "        print(\"圖片和文字已添加到文檔中。\")\n",
        "\n",
        "        # 持續等待新的输入\n",
        "        # if input(\"按Enter繼續或输入'stop'结束: \").lower() == 'stop':\n",
        "        #     break\n",
        "\n",
        "write()\n"
      ],
      "metadata": {
        "id": "iqXZO1DjH066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "b584368c-69c4-4e5f-8568-6ca3ac707340",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "請上傳圖片\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c91ccaac-dfe1-4717-a1ef-55500194342a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c91ccaac-dfe1-4717-a1ef-55500194342a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving final1 (1).png to final1 (1) (1).png\n",
            "圖片和文字已添加到文檔中。\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}